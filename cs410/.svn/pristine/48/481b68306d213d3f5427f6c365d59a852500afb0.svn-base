1) NLP - Natural Language Processing
This is what the computer does in order to understand a sentence
Need to understand the syntax to the sentence
Find the structure of the sentence
Syntactical analysis - We can get most of this
Semantic analysis - This is harder since we don’t know tone and common sense, Works well with some entities and not so well for other entities
Pragmatic analysis - Not quite there yet because inference is hard to determine
Ambiguity is killer to the computer

Can’t do 100% of the speech tagging
Shallow analysis is the best way - the text needs to be general robost & efficient

Feedback - allows us to add aditional words to the query

************************************************************************************************************************************************

2) This part shows the connection between the user and the system and the types of interactions they can have.
Two modes of text access - Push and Pull
Pull - The user takes initiative (Search Engines) - Not so stable
	ad hoc  - temporary infomation
	Querying vs. Browsing
	Querying - Works best when the user knows exactly what keywords to use and the system can retrive the relevant documents
	Browsing - User follows a path in order to get the information that is needed


Push - The system takes initiative (Google maps for giving you information or if you need to do reserach and in order to do so there is a bank of information that the system can refer to and give back) - Stable
	Example - Amazon's reccomended feature

************************************************************************************************************************************************

3) Text Retreval(TR) Problem
Document Selection vs. Document Ranking
Text Retreval is known as search technology in the industry
Text Retreval is an empirically defined problem

Document Selection:
System will decided if a document is relevant or not
	Problems:
	The classifer is unlikely to be accurate
	Hard to find the right position between a document that is 100% relevant (due to incorrently thinking some words made the document completely relevant) versus a document that has no relevance to the search

Document Ranking:
System will only need to decide if a certain document is more relevant than that of another document.

Probability Ranking Principle: Returning a ranked list of documents in descending order of probability that a document is relevant to to the query is the optimal strategy under the following two assumptions
	The use of a document is not dependent on that of another document
	A user would browse the results sequentially


************************************************************************************************************************************************

4) Text Retreval(TR) Methods
	Key Challenge: how to measure the likelihood that document d is relevant to query q
	Retreval Model - Formalization of relevance (give computational definition of relevance)

Many models are equally effective with no single winner

Retrieval Models:

Similarity based models
	Vector spaced model

Probabilistic models
	Classic probabilistic model
	Language model
	Divergence-from-randomness model

Probabilistic inference model

Axiomatic model
	Must satify a set of constraints

BM25 is the most popular model although there are a lot of other models that works just as well 


************************************************************************************************************************************************

5) Vector Space Model
Vector Space Model (VSM) is a framework 
	It represents a doc/query by a term vector
	Concepts are assumed to be orthogonal


************************************************************************************************************************************************

6) Vector Space Model (2)

Simplest VSM:
	Dimension = word
	Vector = 0-1 bit vector (word presnce/absence)
	Similarity = dot product
	f(q,d) = number of distinct query words that were matched in d


************************************************************************************************************************************************

7) Vector Space Model (3)

Term Frequency Vector 
	Now we are considering the times when the number of terms also plays into how we prioritze what we find in documents

Need to add Inverse Document Frequency
	Makes this into a logorithmic function thus allowing us to properly implement word priority


************************************************************************************************************************************************

8) 



















